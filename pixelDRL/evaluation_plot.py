# File partially generated by Google Gemini 3 (For more info, see report Section 7.1) 

import torch
import torch.nn.functional as F
from torch.utils.data import DataLoader
import numpy as np
import os
import argparse
import re
import matplotlib.pyplot as plt
from tqdm import tqdm 

from model import PixelDRL  
from dataset_2d import BraTS2023_Slice_Dataset 

def compute_dice_score(pred, target, smooth=1e-5):
    pred = pred.view(-1)
    target = target.view(-1)
    
    intersection = (pred * target).sum()
    dice = (2. * intersection + smooth) / (pred.sum() + target.sum() + smooth)
    return dice.item()

def save_visualization(img, gt, pred, idx, save_dir):
    img = img.cpu().squeeze().numpy()
    gt = gt.cpu().squeeze().numpy()
    pred = pred.cpu().squeeze().numpy()
    
    plt.figure(figsize=(10, 3))
    
    plt.subplot(1, 3, 1)
    plt.title("MRI Image")
    plt.imshow(img, cmap='gray')
    plt.axis('off')
    
    plt.subplot(1, 3, 2)
    plt.title("Ground Truth")
    plt.imshow(gt, cmap='gray', vmin=0, vmax=1)
    plt.axis('off')
    
    plt.subplot(1, 3, 3)
    plt.title("Prediction")
    plt.imshow(pred, cmap='gray', vmin=0, vmax=1)
    plt.axis('off')
    
    os.makedirs(save_dir, exist_ok=True)
    plt.savefig(f"{save_dir}/result_{idx}.png")
    plt.close()

def evaluate_single_model(model, dataloader, device, t_max):
    model.eval()
    dice_scores = []
    
    with torch.no_grad():
        for i, (image, ground_truth, _) in enumerate(dataloader):
            image = image.to(device)
            ground_truth = ground_truth.to(device)
            
            current_mask = torch.ones_like(image).to(device)
            
            for t in range(t_max):
                state = torch.cat([image, current_mask], dim=1)
                
                policy_logits, _ = model(state)
                probs = torch.sigmoid(policy_logits)
                action = (probs > 0.5).float()
                current_mask = current_mask * action 
            
            dice = compute_dice_score(current_mask, ground_truth)
            dice_scores.append(dice)

    return np.mean(dice_scores), np.std(dice_scores)

def scan_and_evaluate(args):
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"Using device: {device}")

    print("Loading dataset...")
    test_dataset = BraTS2023_Slice_Dataset(root_dir=args.data_dir, split='val_ratio')
    test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False, num_workers=4)
    print(f"Test Set: {len(test_dataset)} images.")

    if not os.path.isdir(args.checkpoint_dir):
        print(f"Error: {args.checkpoint_dir} is not a directory.")
        return

    # Regex to extract epoch number from "pixelDRL_epoch123.pth"
    # Adjust regex if your naming convention is different
    pattern = re.compile(r"pixelDRL_epoch(\d+)\.pth")
    
    checkpoints = []
    for f in os.listdir(args.checkpoint_dir):
        match = pattern.search(f)
        if match:
            epoch = int(match.group(1))
            full_path = os.path.join(args.checkpoint_dir, f)
            if epoch <= 200:
                checkpoints.append((epoch, full_path))
    
    # Sort by epoch
    checkpoints.sort(key=lambda x: x[0])
    
    if not checkpoints:
        print("No checkpoints found matching 'pixelDRL_epoch*.pth' with epoch <= 200")
        return

    print(f"Found {len(checkpoints)} checkpoints.")

    model = PixelDRL(in_channels=2, n_actions=1).to(device)
    
    results = [] # Stores (epoch, mean, std)

    for epoch, pth_path in tqdm(checkpoints, desc="Evaluating Models"):
        try:
            # Load weights
            state_dict = torch.load(pth_path, map_location=device)
            # Handle DataParallel if saved with it
            if list(state_dict.keys())[0].startswith('module.'):
                state_dict = {k[7:]: v for k, v in state_dict.items()}
                
            model.load_state_dict(state_dict)
            
            # Save visuals only for the last model to save space/time
            is_last = (epoch == checkpoints[-1][0])
            viz_dir = os.path.join(args.checkpoint_dir, "plots", f"epoch_{epoch}")
            
            mean_dice, std_dice = evaluate_single_model(
                model, test_loader, device, args.t_max
            )
            
            results.append((epoch, mean_dice, std_dice))
            
        except Exception as e:
            print(f"\nFailed to load/eval {pth_path}: {e}")

    # 4. Process Results
    epochs = [r[0] for r in results]
    means = [r[1] for r in results]
    stds = [r[2] for r in results]

    best_idx = np.argmax(means)
    best_epoch = epochs[best_idx]
    best_dice = means[best_idx]
    best_std = stds[best_idx]

    print("\n" + "="*40)
    print("FINAL RESULTS")
    print("="*40)
    print(f"Best Model: Epoch {best_epoch}")
    print(f"Best Dice:  {best_dice:.4f}")
    print("-" * 40)

    # 5. Plotting
    plt.figure(figsize=(10, 6))
    plt.plot(epochs, means, marker='o', linestyle='-', color='b', label='Mean Dice')
    
    # Optional: Fill standard deviation
    lower_bound = np.array(means) - np.array(stds)
    upper_bound = np.array(means) + np.array(stds)
    
    # Clip to 0-1 range for valid Dice
    lower_bound = np.clip(lower_bound, 0, 1)
    upper_bound = np.clip(upper_bound, 0, 1)
    
    
    plt.title(f"Training Progress: Dice Score vs Epoch\n(Best: {best_dice:.4f} at Epoch {best_epoch})")
    plt.xlabel("Epoch")
    plt.ylabel("Dice Score")
    plt.grid(True, linestyle='--', alpha=0.7)
    plt.legend()
    
    plot_path = os.path.join(args.checkpoint_dir, "dice_vs_epoch.png")
    plt.savefig(plot_path)
    print(f"Graph saved to: {plot_path}")
    print("="*40)

if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("--data_dir", type=str, required=True, help="Path to BraTS folder")
    parser.add_argument("--checkpoint_dir", type=str, required=True, help="Path to DIRECTORY containing .pth files")
    parser.add_argument("--t_max", type=int, default=10, help="Number of steps for agent")
    
    args = parser.parse_args()
    
    scan_and_evaluate(args) 