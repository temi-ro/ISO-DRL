# File entirely generated by Google Gemini 3 (For more info, see report Section 7.1)
from tqdm import tqdm
import torch
from torch.utils.data import DataLoader
import matplotlib.pyplot as plt 

import torch.nn as nn
from dataset_2d import BraTS2023_Slice_Dataset

def visualize_sample(image, ground_truth, step, name="sample"):
    """Saves a .png comparing Image, GT, and Current Mask"""
    image_np = image.squeeze().cpu().numpy()
    gt_np = ground_truth.squeeze().cpu().numpy()
    
    plt.figure(figsize=(12,4))
    
    plt.subplot(1,2,1)
    plt.title("Input Image")
    plt.imshow(image_np, cmap='gray')
    plt.axis('off')
    
    plt.subplot(1,2,2)
    plt.title("Ground Truth")
    plt.imshow(gt_np, cmap='gray')
    plt.axis('off')
    
    # plt.savefig(f"{save_dir}/{name}_step{step}.png")
    print(f"Saved visualization: {name}_step{step}.png")
    plt.show()
    plt.close()


if __name__ == "__main__":
    # visualise a sample from the dataset

    dataset_path = "/home/temi/ICL/ISO/brats2023/training_raw/Dataset001_BraTS2023/"
    dataset = BraTS2023_Slice_Dataset(dataset_path, split='val_tiny')
    dataloader = DataLoader(dataset, batch_size=1, shuffle=True)
    scale = 10.0

    for i, (images, rl_targets, binary_masks) in enumerate(tqdm(dataloader)):

        image = images.squeeze(0)  # Remove batch dim
        ground_truth = binary_masks.squeeze(0)  # Remove batch dim
        current_mask = torch.ones_like(image).to("cpu")
        pixel_map = ground_truth * (15 - 1) + 1.0

        print(f"Image shape: {image.shape}, Ground Truth shape: {ground_truth.shape}")
        print(f"Unique values in Ground Truth: {torch.unique(ground_truth)}")

        diff = torch.square(current_mask - ground_truth)
        prev_diff = diff * 250/255
        
        
        reward = diff - prev_diff
        reward = reward * pixel_map * scale

        diff_mean = torch.mean(diff)
        diff_sum = torch.sum(diff)
        diff_mean_scaled = torch.sign(diff_mean) * torch.log(1 + torch.abs(diff_mean))

        # supervised anchor loss
        supervised_loss_acum = 0.0
        bce_criterion = nn.BCEWithLogitsLoss()
        supervised_loss_acum += bce_criterion(current_mask.unsqueeze(0), ground_truth.unsqueeze(0).unsqueeze(0))
        supervised_loss = supervised_loss_acum / 1
        
        print(f"Supervised Loss: {supervised_loss.item()}")
        print(f"Difference shape: {diff.shape}")
        print(f"Reward: {reward}")
        print(f"Initial difference (sqrt sum): {torch.sum(diff).item()}")
        print(f"Mean pixel value in Ground Truth: {torch.mean(diff).item()}")
        print(f"Log-scaled mean difference: {diff_mean_scaled.item()}")
        # visualize_sample(image, ground_truth, step=0, name=f"sample_{i}")
        
        if i >= 2:  # Visualize only first 3 samples
            break   